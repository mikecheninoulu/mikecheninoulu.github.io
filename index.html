
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
<link rel="shortcut icon" type="image/x-icon" href="teasers/favicon.ico" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  
<title>Haoyu Chen | University of Oulu</title>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  <link href="css/style.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="js/hidebib.js"></script>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-40545479-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>


</head>

<body>
  <div class="container">
    <table width="900" border="0" align="center" cellpadding="20">
      <table width="90%" align="center" border="0" cellpadding="10">
        <tr>
          <td width="70%" valign="top">
            <p align="center">&nbsp;</p>

            <p align="center"><font size="6px">Haoyu Chen | University of Oulu</font><br>
           chen.haoyu@oulu.fi</p>

            <p>I am now a Tenure-track Assistant Professor at <a href="https://www.oulu.fi/en/university/faculties-and-units/faculty-information-technology-and-electrical-engineering/center-machine-vision-and-signal-analysis">CMVS, University of Oulu</a>. 
              Before that, I conducted Postdoc research in <a href="https://www.oulu.fi/en/university/faculties-and-units/faculty-information-technology-and-electrical-engineering/center-machine-vision-and-signal-analysis">CMVS, University of Oulu</a>, with the project of in Emotion AI (Academy Finland project) and trustworthy AI (Infotech project). I received my Ph.D. from <a href="https://www.oulu.fi/en"> University of Oulu </a>, Finland, 
              where I was advised by Academy Professor <a href="https://gyzhao-nm.github.io/Guoying/">Guoying Zhao</a>. During my PhD study, I visited <a href="https://www.educationandlearning.nl/home">CEL, TUDelft, the Netherlands</a>. Prior to that, I received the B.E. degree from <a href="https://en.cug.edu.cn/" target="_blank">China University of Geosciences</a>, China, and Master degree from <a href="https://www.oulu.fi/en" target="_blank">University of Oulu</a>, Finland.</p>

              <p>My research interests include <b>Machine Learning</b>, <b>Human Behaviour Analysis</b>, <b>Emotion AI</b> and <b>Adversarial Learning</b>.</p>

	      <p>I strongly believe we are here, on this planet, time, and realm to experience, learn and grow, which gives me a huge passion about developing myself in a lifetime. Aside from research, I also find huge interest in street dance (Breakin), snowboarding, basketball, Twitch streaming, reading, writing blogs, keeping daily dairy, and Lonkero.</p>

	      <p><b>Attention</b>: We are recruiting self-motivated PostDoc and PhD candidates to join my research team, focusing on Hybrid Intelligence. Please email me with your CV and motivation letter if you are interested in self-funded studying or researching.</p>


            <p> <a href="https://smartblogchen.wordpress.com/" target="_blank" ><img src="icons/wordpress.png" height="36"></a> / 
                <a href="https://scholar.google.com/citations?user=QgbraMIAAAAJ&hl=en" target="_blank"><img src="icons/google_scholar.png" height="26"></a> /
                <a href="https://github.com/mikecheninoulu" target="_blank" ><img src="icons/github_alt.png" height="26"></a>/
                <a href="https://orcid.org/my-orcid?orcid=0000-0003-3267-2664" target="_blank" ><img src="icons/orcid.png" height="26"></a>
            </p>
		  
          </td>
          <td width="30%">
            <div class="instructorphoto">
              <img onmouseover="document.getElementById('georgia').src='teasers/me_in_crazy.JPG';"
              onmouseout="document.getElementById('georgia').src='icons/rsz_chenhaoyu1.png';"src="icons/rsz_chenhaoyu1.png" id="georgia">
            </div>
          </td>
        </tr>
      </table>
    </table>
  </div>
  <br>

  <div class="container">
    <table width="90%" border="0" align="center" cellpadding="20">
    <h2>News</h2>
      <div class="news">
        <ul>      
	<li><span> [2024.05] We organized the <a href=" https://www.oulu.fi/en/events/hi-lights-seminar-achieving-hybrid-intelligence-data-and-algorithm-aspect">HI lights seminar</a> and I successfully hosted the <a href="https://www.linkedin.com/posts/hybrid-intelligence-human-ai-co-evolution-and-learning-in-multi-realities-hi_hybridintelligence-ai-human-activity-7201596185567006723-2riV?utm_source=share&utm_medium=member_desktop"> whole day session</a>. Thanks for the excellent keynote talks and panel discussion from the scientific advisor board members!</span></li>
	<li><span> [2024.05] I gave a talk on  <a href="https://www.oulu.fi/en/events/brown-bag-seminar-challenge-emotions-for-artificial-intelligence-and-humans-what-can-we-learn-about">Brown Bag Seminar</a>: 'The challenge of emotions for artificial intelligence and humans – what can we learn about it?', at the University of Oulu.</span></li>
	<li><span> [2024.05] I gave a talk about Human emotion understanding via human behaviors and go beyond on ITEE TENURES ON STAGE event, University of Oulu.</span></li>
	<li><span> [2024.04] We launched the 2nd <a href="https://cv-ac.github.io/MiGA2/"> Workshop & Challenge on Micro-gesture Analysis for Hidden Emotion Understanding (MiGA)</a> associated with <a href="https://ijcai-24.org/"> IJCAI 2024</a>, submission and participation are warmly welcome.</span></li>
           <li><span> [2024.03] I'm co-editing the <b>Frontiers in Physics</b> with topic on <a href="https://www.frontiersin.org/research-topics/63494/advanced-deep-learning-algorithms-for-multi-source-data-and-imaging">Advanced Deep Learning Algorithms for Multi-Source Data and Imaging</a>, welcome to submit your papers</span></li>
	   <li><span> [2024.03] One first-authored paper is accepted by <b>CVPR 2024</b> about 3D pose transfer with adversarial training.</span></li>
           <li><span> [2024.03] Our tutorial about Human-AI mutual promotion for emotion and cognition understanding(<a href="https://cv-ac.github.io/HAECU-HHAI2024/">website here</a>) is accepted by <b>HHAI 2024</b>, June 10-14 2024, Malmö, Sweden. Welcome to join! <a href="https://hhai-conference.org/2024/"> HHAI 2024)</a>.</span></li>
           <li><span> [2024.02] I start my new position as <b>a tenure-track assistant professor</b> in CMVS (<a href="https://www.oulu.fi/en/news/haoyu-chen-started-tenure-track-professor-hybrid-intelligence-programme-university-oulu">news here</a>), University of Oulu, Finland, with the project of <a href="https://www.oulu.fi/en/research/strengthening-human-capabilities-digital-era/hybrid-intelligence-human-ai-co-evolution-and-learning-multi-realities-hi"> Hybrid Intelligence (Academy of Finland in the Profi7)</a>, recruiting a Ph.D. student and a Postdoc researcher (please email me for details).</span></li>
	   <li><span> [2023.12] We are organizing the <b>BJET special section</b> for <a href="https://bera-journals.onlinelibrary.wiley.com/hub/journal/14678535/cfp-hybrid-intelligence">Hybrid Intelligence</a>, welcome to submit your papers.</span></li>
	  <li><span> [2023.09] One co-authored paper is accepted by <b>AAAI 2024</b>.</span></li>
	  <li><span> [2023.09] Our paper about 3D motion transfer is accepted by <b>NeurIPS 2023</b>.</span></li>
	   <li><span> [2023.09] We successfully held the first <b>MiGA workshop & Challenge on IJCAI conference</b>, Macao.</span></li>	
	   <li><span> [2023.06] I started my visit to Wuhan University, China, and Huazhong University of Science and Technology (HUST) for three months.</span></li>
          <li><span> [2023.04] We launched the 1st <a href="https://cv-ac.github.io/MiGA2023/"> Workshop & Challenge on Micro-gesture Analysis for Hidden Emotion Understanding (MiGA)</a> associated with <a href="https://ijcai-23.org/"> IJCAI 2023</a> .</span></li>
          <li><span> [2023.03] I will give lectures on <a href="https://moodle.oulu.fi/course/view.php?id=17361">Computer Graphics</a> course (March - May) in University of Oulu.</span></li>
          <li><span> [2023.02] Our paper about SMG dataset and micro-gestures is accepted by <b>IJCV 2023</b>.
          <li><span> [2022.10] Our TIP paper on Gesture Recognition has been granted <b>'The second prize of IEEE Finland Jt. Chapter SP/CAS Best Paper Award'</b>.
          <li><span> [2022.03] I start my visit to <a href="https://www.educationandlearning.nl/home">CEL, TUDelft, the Nehterlands</a> for three months.</span></li>
          <li><span> [2022.03] I have successfully defended my <b>doctoral thesis</b> with a grade of '<strong> Distinction </strong>'. The thesis can be downloaded <a href="http://jultika.oulu.fi/Record/isbn978-952-62-3239-3">here</a>.</span></li>
          <li><span> [2022.02] Our paper about generalized 3D pose transfer is accepted by <b>AAAI 2022</b>.</span></li> 
          <li><span> [2021.10] I give a short talk about gestural emotional AI on Machine Vision Group 40th Anniversary.</span></li>
          <li><span> [2021.06] Our paper about unsupervised 3D pose transfer is accepted by <b>ICCV 2021</b>.</span></li> 
          <li><span> [2021.02] Our paper about iMiGUE dataset and micro-gestures is accepted by <b>CVPR 2021</b>.</span></li> 
          <li><span> [2020.08] We got the 2nd Place on Action Recognition Track of <a href="https://vipriors.github.io/2020/">ECCV 2020 VIPriors Challenges</a>.</span></li> 
          <li><span> [2020.04] Our paper about online gesture recognition is accepted by <b>TIP 2020</b></a>.</span></li> 
        </ul>
      </div>
    </table>
  </div>
  <br>

  <div class="container">
    <h2> Selected Publications </h2>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/cvpr.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><b>Towards Robust 3D Pose Transfer with Adversarial Learning</b><br>
          <strong>Haoyu Chen</strong>, Hao Tang, Ehsan Adeli, Guoying Zhao. <em>Computer Vision and Pattern Recognition(CVPR) </em>, 2024. <br>
         
        </td> 
        </td>
      </table>
    </div>

    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/lart.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://openreview.net/forum?id=g27BggUT3L&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DNeurIPS.cc%2F2023%2FConference%2FAuthors%23your-submissions)"><b>LART: Neural Correspondence Learning with Latent Regularization Transformer for 3D Motion Transfer</b></a><br>
          <strong>Haoyu Chen</strong>, Hao Tang, Radu Timofte, Luc Van Gool, Guoying Zhao. <em>Neural Information Processing Systems (NeurIPS) </em>, 2023. <br>
         
        </td> 
        </td>
      </table>
    </div>
	  
    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/smg.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://link.springer.com/article/10.1007/s11263-023-01761-6"><b>SMG: A Micro-Gesture Dataset Towards Spontaneous Body Gestures for Emotional Stress State Analysis</b></a><br>
          <strong>Haoyu Chen</strong>, Henglin Shi, Xin Liu, Xiaobai Li, Guoying Zhao. <em> International Journal on Computer Vision (IJCV)</em>, 2023. <br>
         <a href="https://github.com/mikecheninoulu/SMG">Code</a>
         
        </td> 
        </td>
      </table>
    </div>
  
  <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/gct.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/19901"><b> Geometry-Contrastive Transformer for Generalized 3D Pose Transfer​</b></a><br>
          <strong>Haoyu Chen</strong>, Hao Tang, Zitong Yu, Nicu Sebe, Guoying Zhao​. <em> AAAI Conference on Artificial Intelligence (AAAI) </em>, 2022. <br>
	  <a href="https://github.com/mikecheninoulu/CGT">Code</a>
         
        </td> 
        </td>
      </table>
    </div>
  
  <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/aniformer.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://www.bmvc2021-virtualconference.com/conference/papers/paper_0130.html"><b>AniFormer: Data-driven 3D Animation with Transformer. </b></a><br>
          <strong>Haoyu Chen</strong>, Hao Tang, Nicu Sebe, Guoying Zhao. <em> The British Machine Vision Conference (BMVC)</em>, 2021. <br>
          <a href="https://github.com/mikecheninoulu/AniFormer">Code</a>
        </td> 
        </td>
      </table>
    </div>
  
  <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/pose.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Intrinsic-Extrinsic_Preserved_GANs_for_Unsupervised_3D_Pose_Transfer_ICCV_2021_paper.pdf"><b>Intrinsic-extrinsic preserved gans for unsupervised 3D pose transfer</b></a><br>
          <strong>Haoyu Chen</strong>, Hao Tang, Henglin Shi, Wei Peng, Nicu Sebe, Guoying Zhao. <em> IEEE International Conference on Computer Vision (ICCV)</em>, 2021. <br>
          <a href="https://github.com/mikecheninoulu/Unsupervised_IEPGAN">Code</a>
        </td> 
        </td>
      </table>
    </div>
  

  <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/iMiGUE_short2.gif" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_iMiGUE_An_Identity-Free_Video_Dataset_for_Micro-Gesture_Understanding_and_Emotion_CVPR_2021_paper.html"><b>iMiGUE: An Identity-Free Video Dataset for Micro-Gesture Understanding and Emotion Analysis</b></a><br>
          Xin Liu, Henglin Shi, <strong>Haoyu Chen</strong>, Zitong Yu, Xiaobai Li, Guoying Zhao. <em> IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021. <br>
        <a href="https://github.com/linuxsino/iMiGUE">Code</a>
        </td> 
        </td>
      </table>
    </div>

  <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/thdhmm.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QgbraMIAAAAJ&sortby=pubdate&citation_for_view=QgbraMIAAAAJ:YsMSGLbcyi4C"><b>Temporal hierarchical dictionary guided decoding for online gesture segmentation and recognition</b></a><br>
          <strong>Haoyu Chen</strong>, Xin Liu, Jingang Shi, Guoying Zhao. <em> IEEE Transactions on Image Processing</em>, 2020. <br>
          <a href="https://github.com/mikecheninoulu/THDHMMBiLSTM">Code</a>
        </td> 
        </td>
      </table>
    </div>

<div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/Searched.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="http://jultika.oulu.fi/files/nbnfi-fe2020120399293.pdf"><b>Searching Multi-Rate and Multi-Modal Temporal Enhanced Networks for Gesture Recognition</b></a><br>
          Zitong Yu, Benjia Zhou, Jun Wan, Pichao Wang, <strong>Haoyu Chen</strong>, Xin Liu, Stan Z Li, Guoying Zhao. <em> IEEE Transactions on Image Processing (TIP)</em>, 2020. <br>
        <a href="https://github.com/ZitongYu/3DCDC-NAS">Code</a>
        </td> 
        </td>
      </table>
    </div>

  <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/nas_gcn.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/5652/5508"><b>Learning graph convolutional network for skeleton-based human action recognition by neural searching</b></a><br>
          Wei Peng, Xiaopeng Hong, <strong>Haoyu Chen</strong>, Guoying Zhao. <em> The Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI)</em>, 2020. <br>
           <a href="https://github.com/xiaoiker/GCN-NAS">Code</a>
        </td> 
        </td>
      </table>
    </div>

 <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="40%" valign="center"><img src="teasers/hiddenstate.png" alt="game" width="180" height="120" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="http://jultika.oulu.fi/files/nbnfi-fe2020042322156.pdf"><b>3D skeletal gesture recognition via hidden states exploration</b></a><br>
          Xin Liu, Henglin Shi, Xiaopeng Hong, <strong>Haoyu Chen</strong>, Dacheng Tao, Guoying Zhao. <em> IEEE Transactions on Image Processing</em>, 2020. <br>
        </td> 
        </td>
      </table>
    </div>
    <hr>

   <div class="container">
    <table width="90%" border="0" align="center" cellpadding="20">
    <h2>Academic Activities</h2>
      <div class="Academic Activities">
        <ul> 
	<li><span> Organizing tutorial about Human-AI mutual promotion for emotion and cognition understanding(<a href="https://cv-ac.github.io/HAECU-HHAI2024/">website here</a>)</b>, June 10-14 2024, Malmö, Sweden. <a href="https://hhai-conference.org/2024/"> HHAI 2024)</a>.</span></li>
         <li><span> Giving talks on ITEE TENURES ON STAGE event, Brown Bag Seminar, University of Oulu.</span></li>
         <li><span>  Serving as co-editors on the <b>Frontiers in Physics</b>, <b>British Journal of Educational Technology</b>, </span></li>
         <li><span> Organizing the 1st/2nd <a href="https://cv-ac.github.io/MiGA2023/"> Workshop & Challenge on Micro-gesture Analysis for Hidden Emotion Understanding (MiGA)</a> associated with <a href="https://ijcai-23.org/"> IJCAI 2023</a>/ <a href="https://ijcai-24.org/"> IJCAI 2024</a>.</span></li>
         <li><span> Providing data support to <a href="https://mikecheninoulu.github.io/SIG-CV/"> Finnish Center for Artificial Intelligence Special Interest Group (FCAI-SIG)-Computer Vision</a>.</span></li>
         <li><span> Invited as Reviewer for conferences, including CVPR2023, AAAI2023, ICASSP2023, ECCV2022, ICME2022, etc.</span></li>
          <li><span> Invited as Reviewer for journals, including IEEE Transactions on Multimedia (TMM), IEEE Transactions on Neural Networks and Learning Systems (TNNLS),  IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), Pattern Recognition (PR), Machine Vision and Applications, Multimedia Systems, British Journal of Educational Technology, Advanced Engineering Informatics, etc.</span></li>
        </ul>
      </div>
    </table>
  </div>
  <br>


<div class="container">
    <table width="90%" border="0" align="center" cellpadding="20">
    <h2>Teaching Experiences</h2>
      <div class="Teaching">
        <ul> 
	  <li><span> Lecturer, Affective Computing, Univerisity of Oulu -- Fall 2024 (upcoming)</span></li>
	  <li><span> Lecturer, Computer Graphics, Univerisity of Oulu -- Spring 2024</span></li>
          <li><span> Lecturer, Computer Graphics, Univerisity of Oulu -- Spring 2023</span></li>
          <li><span> Teaching Assistant, Computer Graphics, Univerisity of Oulu -- Spring 2022</span></li>
          <li><span> Teaching Assistant, Computer Graphics, Univerisity of Oulu -- Spring 2020</span></li>
          <li><span> Teaching Assistant, Affective computing, Univerisity of Oulu -- Fall 2018</span></li>
        </ul>
      </div>
    </table>
  </div>
  <br>

<table style="width:40%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
      <td style="padding:30px">
<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=AVZyykr8LeIDVHzYCZhPtzV-Y8YJfQZbm0JkG0m7wqM"></script>
      </td>
  </tr>
</tbody></table>
  

<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>


          
</body>
</html>
